# 1. Kafka 개요

데이터 중심 시대에서 Kafka(Kafka) 는 고성능 실시간 데이터 처리를 위한 필수 기술로 자리 잡았다.
Kafka는 링크드인(LinkedIn) 이 데이터 파이프라인 확장 문제, 이기종 간 호환성 부족, 실시간 처리 성능 문제를 해결하기 위해 2010년 개발했으며, 2011년 아파치 오픈소스로 공개되었다.

주요 특징

- Pub/Sub 모델 기반으로 실시간 데이터 반영
- 고성능 분산 처리를 통한 대량 데이터 처리 지원
- 이벤트 스트리밍을 통한 데이터 변경 사항 전파

## 1.1. 잘란도와 트위터 Kafka 도입 사례

질란도(2020년도)

- 실사용자 수 3,100만 명
- 연간 주문수 1억 4,5000만 건
- 상품 판매 건수 50만 건
- 5년간 연평균 성장률 24%
- 거래액은 약 10조 원 규모

클라이언트들이 데이터에 대한 온갖 요구사항이 불거졌다.

이에 이벤트 드리븐 시스템으로 전환을 결정 했다. 기존 pull 방식에서 push 방식으로 데이터를 제공하여, 데이터 변경 사항은 이벤트 스트리밍을 통해 소비자에게 전달되며, 소비자들은 이를 구독하고 적절히 처리할 수 있도록 설계되었다.

[이벤트 드리븐 시스템 도입을 통해 데이터를 소비하는 컨슈머들은 자신의 요구사항에 따라 데이터를 처리하거나 구독할 수 있게 됐다.](https://engineering.zalando.com/posts/2017/10/event-first-development---moving-towards-kafka-pipeline-applications.html)

### 1.1.1. 프로토타입 개발과 문제점 발견

잘란도(Zalando)는 빠르게 성장하는 전자상거래 기업으로, 기존의 동기식 API + PostgreSQL 기반 아키텍처에서 다음과 같은 문제를 겪었다.

- 데이터 일관성 문제: 네트워크 환경에서 이벤트가 누락될 가능성
    - 네트워크 환경에서 이벤트를 정확하게 전달하는 문제
    - 이벤트 드리븐 시스템에서 가장 중요한 것은 인바운드 데이터와 아웃바운드 데이터의 일치성이다.
    - 데이터의 신뢰성과 정합성을 보장해야 한다.
    - 여러 네트워크를 이용하는 환경에서 모든 데이터 변경을 올바르게 전달하는 문제
- 순서 보장 어려움: 동시 수정 시 이벤트 처리 순서 유지 문제
    - 동일 데이터에 대한 동시 수정(concurrent modification) 시 올바른 이벤트 순서를 유지하는 문제
    - 데이터 검증 부담 증가
    - 다양한 클라이언트 요구사항을 효율적으로 지원하기 어려움
- 실시간·대량 처리 문제: 다양한 소비자 요구(실시간 vs 배치) 충족 어려움
    - 빠른 전송이 필요한 클라이언트와 대량 배치 전송을 원하는 클라이언트를 동시에 지원하기 어려움

### 1.1.2. Kafka 기반의 비동기 이벤트 소싱(Event Sourcing) 모델로 전환

잘란도는 기존 아키텍처를 이벤트 소싱(Event Sourcing) 모델로 전환하고, Kafka 를 중심으로 비동기 이벤트 처리 방식을 채택했다.

#### Kafka 도입 효과

- 고성능 데이터 처리: HTTP 기반 전송에도 밀리초(ms) 단위 응답 속도 확보
- 이벤트 순서 보장: 동시 수정 문제 해결, 데이터 정합성 향상
- 안정적인 데이터 전송: 적어도 한 번(at-least-once) 원칙으로 데이터 손실 방지
    - `누락없는 재전송 가능`
    - 분산 시스템 환경에서의 데이터 처리에서 중요한건 멱등성(idempotent)다.
    - 멱등성이란 동일한 작업을 여러 번 수행하더라도 결과가 달라지면 안된다.
- 백프레셔(Backpressure) 처리: 컨슈머가 자신의 속도로 데이터 처리 가능
    - Kafka 클라이언트는 pull 방식으로 동작한다.
    - 각 Kafka 클라이언트들은 자기 자신의 속도로 데이터를 처리할 수 있다.
    - 성능과 편리함에 집중하고자 풀 방식을 채택했다.
- 수평 확장 지원: Kafka 파티션을 활용해 처리량 확장
- 이벤트 로그 저장 및 스냅샷 제공: 로그 컴팩션(Log Compaction) 지원
- 느슨한 결합 시스템 구축: 서비스 간 독립성 증가, 유지보수 용이
- Pub/Sub 모델 지원
    - 실시간 변경된 데이터 노출 가능
    - 수평 확장이 용이하며 고가용성을 갖춘 시스템

### 1.1.2.1. 이벤트 버스 VS Kafka

트위터는 Kafka 도입 후, 60~70% 리소스를 절감하고 운영 비용을 대폭 감소시킬 수 있었다.

| 비교 항목   | 	Kafka                    | 	이벤트 버스                   |
|---------|---------------------------|---------------------------|
| 데이터 지연  | 	거의 없음 (BPS 영향 적음)        | 	서빙 레이어·스토리지 분리로 추가 지연 발생 |
| 스토리지 방식 | 	로그 기반 (Append-Only)      | 	파일 시스템 기반 (fsync 블로킹)    |
| 처리 방식   | 	OS 기반 비동기 처리 (zero-copy) | 	fsync() 호출 시 블로킹 발생      |
| 하드웨어 요구 | 	상대적으로 적음 (리소스 절감 효과)     | 	추가적인 인프라 필요              |

이벤트 버스는 fsync() 호출 시 블로킹(Blocking) 이 발생하지만, Kafka는 데이터를 OS의 페이지 캐시(Page Cache) 에 먼저 저장한 후, 백그라운드에서 디스크로 플러시(Flush) 한다.

즉, Kafka는 fsync()를 즉시 호출하지 않기 때문에 프로듀서의 요청이 블로킹되지 않으며, 비동기처럼 동작한다.

> 디스크 → 커널 버퍼 → ~~사용자 공간~~ → 소켓 버퍼 → 네트워크<br/>Zero-Copy는 데이터를 사용자 공간(User Space) 으로 복사하지 않고, 커널 공간(Kernel Space) 에서 직접 전송하는 기술이다. Kafka는 sendfile()을 활용해 Zero-Copy를 구현함으로써 성능을 극대화하고 있다.

Kafka는 다양한 내부 문제를 해결하는 데 효과적으로 활용될 수 있다. 만약 다음과 같은 고민이 있다면, Kafka 도입을 고려해보자.

- 동기/비동기 데이터 전송 방식에 대한 고민이 있는가?
- 실시간 데이터 처리가 필요한가?
- 현재 데이터 처리 성능에 한계를 느끼는가?
- 새로운 데이터 파이프라인 구축이 복잡하다고 생각하는가?
- 데이터 처리 비용 절감이 중요한가?

## 1.2. 국내외 Kafka 이용 현황

Kafka는 글로벌 기업의 핵심 데이터 처리 기술이다.

- 넷플릭스, 우버, 링크드인, 쿠팡 등 **데이터 중심 기업들이 Kafka를 적극 활용**
- 실시간 데이터 스트리밍, 로그 분석, 추천 시스템, 장애 감지 등 다양한 용도로 사용
- 높은 처리량과 확장성 덕분에 글로벌 대기업에서 필수적인 기술

### 기업별 Kafka 활용 사례

| 기업        | 도입 이유                                      | 활용 사례                                                             | 도입 효과                                                        |
|-------------|------------------------------------------------|----------------------------------------------------------------------|-----------------------------------------------------------------|
| 아디다스     | 글로벌 전자상거래 확장과 데이터 통합 문제 해결 | Kafka 기반 데이터 스트리밍 플랫폼 구축                                 | - 데이터 지연 최소화 → 실시간 사용자 경험 개선                  <br/> - 빠른 오류 감지 및 대응으로 서비스 안정성 향상              |
| 데이터독    | 대량의 메트릭 및 로그 데이터 처리 최적화        | Kafka를 중앙 이벤트 파이프라인으로 활용                               | - 실시간 데이터 모니터링 성능 향상                               <br/> - 대규모 트래픽 환경에서도 고가용성(HA) 유지                 |
| 넷플릭스    | 글로벌 콘텐츠 스트리밍 최적화 및 실시간 데이터 분석 | Kafka를 사용자 행동 데이터 처리 및 추천 시스템에 활용                | - 실시간 추천 알고리즘 최적화 → 사용자 경험 개선               <br/> - 장애 탐지 및 대응 시간 단축                               |
| 우버        | 실시간 차량 매칭 및 요금 계산 최적화           | Kafka를 실시간 데이터 처리 및 분석에 사용                            | - 요청-응답 지연 시간 감소 → 빠른 차량 배차 가능               <br/> - 대규모 트래픽 처리 가능                                   |
| 링크드인    | 실시간 데이터 흐름 및 사용자 맞춤 서비스 개선  | Kafka를 실시간 이벤트 로깅 및 분석에 사용                            | - 초당 수백만 건의 메시지 처리 가능                             <br/> - 데이터 일관성 유지 및 비즈니스 로직 최적화                 |
| 쿠팡        | 빠른 상품 검색 및 주문 시스템 안정화           | Kafka를 데이터 처리 및 분산 시스템에 활용                            | - 실시간 데이터 분석을 통한 검색 최적화                        <br/> - 장애 발생 시 빠른 감지 및 복구                            |

## 1.3. Kafka의 주요 특징

- 높은 처리량과 낮은 지연 시간
  - Kafka는 높은 처리량과 낮은 지연 시간을 제공하여 실시간 데이터 스트리밍에 최적화되어 있다. 초당 수백만 건의 메시지를 처리할 수 있는 성능을 자랑한다.
- 높은 확장성
  - Kafka는 수평 확장성이 뛰어나, 데이터가 증가하더라도 추가적인 리소스를 쉽게 확보하여 처리 능력을 확장할 수 있다.
- 고가용성 (High Availability)
  - Kafka는 분산 시스템으로 설계되어 리더-팔로워 모델을 사용하고, 장애 발생 시에도 서비스가 지속될 수 있도록 고가용성을 제공한다. 이를 통해 데이터 복제 및 장애 복구가 원활하게 이루어진다.
- 내구성
  - Kafka는 메시지 내구성을 위해 acks 옵션을 제공한다. acks 옵션을 "0", "1", "all" 등으로 설정하여 메시지의 내구성을 조절할 수 있다.
  - Kafka로 전송되는 모든 메시지는 분산된 디스크에 안전하게 저장되어, 장애나 시스템 다운 시에도 데이터를 잃지 않도록 보장된다.
- 개발 편의성
  - Kafka는 메시지를 전송하는 프로듀서와 메시지를 가져오는 컨슈머를 완전히 분리하여, 각자가 독립적으로 동작하고 서로 영향을 주지 않는다. 프로듀서는 메시지 전송 로직만 구현하면 되며, 컨슈머는 메시지 소비 로직만 구현하면 된다.
  Kafka Connect는 다양한 외부 시스템과의 데이터 통합을 지원하며, Schema Registry는 메시지 스키마의 버전 관리를 돕는다.
- 운영 및 관리의 편의성
  - Kafka는 분산 시스템으로서 운영 및 관리가 용이하도록 설계되었다. 클러스터 모니터링, 로그 관리, 파티션 관리 등 다양한 관리 기능을 제공하며, 고가용성 및 내구성을 지원하는 기능도 포함되어 있다.

## 1.4. Kafka의 성장

- v0.8: 리플리케이션 기능 추가
  - Kafka가 분산 시스템으로서의 강점을 확립한 버전. 데이터의 내구성과 고가용성을 보장하기 위해 리플리케이션 기능이 추가되었다.
- v0.8.2: 스키마 레지스트리 공개
  - Kafka에서 메시지의 스키마 관리가 가능하게 되었으며, 이를 통해 데이터의 구조적 일관성을 유지할 수 있다. Schema Registry는 주로 Avro, JSON 등의 스키마를 관리하는 데 사용된다.
- v0.9: Kafka 커넥트 공개
  - 외부 시스템과의 연동을 용이하게 하는 Kafka Connect가 공개되었다. 이를 통해 Kafka는 다양한 데이터베이스, 파일 시스템, 클라우드 서비스와 쉽게 연결할 수 있게 되었다.
- v0.10: Kafka 스트림즈 공개
  - Kafka Streams 라이브러리가 도입되어, Kafka를 기반으로 한 스트리밍 애플리케이션을 작성할 수 있게 되었다. 이 라이브러리는 분산 스트리밍 처리 기능을 제공하며, 개발자들이 복잡한 스트리밍 작업을 쉽게 구현할 수 있도록 도와준다.
- KSQL 공개
  - KSQL은 Kafka에서 스트리밍 데이터를 SQL-like 방식으로 처리할 수 있게 해주는 쿼리 언어로, 스트리밍 데이터의 실시간 쿼리 및 변환을 쉽게 할 수 있도록 한다. KSQL은 Kafka
    Streams와 결합하여 더욱 직관적인 실시간 데이터 처리가 가능하게 한다.
- v3.0: 주키퍼 의존성에서 해방
  - Kafka는 더 이상 Zookeeper에 의존하지 않게 되었으며, 자체적인 메타데이터 관리 시스템을 도입하여 성능을 더욱 향상시켰다. 이를 통해 시스템의 안정성과 관리가 용이해졌다.

## 1.5. 다양한 Kafka의 사용 사례

- [데이터 파이프라인 - 넷플릭스](https://netflixtechblog.com/evolution-of-the-netflix-data-pipeline-da246ca36905)
- [데이터 통합 - 우버](https://www.uber.com/en-KR/blog/ureplicator-apache-kafka-replicator/)
- [머신러닝 분야 활용 사례](https://www.confluent.io/blog/build-deploy-scalable-machine-learning-production-apache-kafka/)
- [데이터 스트리밍 - Tesla](https://www.kai-waehner.de/blog/2025/02/14/tesla-energy-platform-the-power-of-data-streaming-with-apache-kafka/)
